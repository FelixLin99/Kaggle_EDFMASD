{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "from PIL import Image\n",
    "import glob\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_DATASET = ['./DROWSY/**', './FOCUSED/**', 'UNFOCUSED/**']\n",
    "ACTIVATION = 'relu'\n",
    "PREDICT_ACTIVATION = 'softmax'\n",
    "OPTIMIZER = 'adam'\n",
    "LOSS = 'categorical_crossentropy'\n",
    "METRICS = ['accuracy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_arguments():\n",
    "    \"\"\"\n",
    "    Function used to parse script arguments\n",
    "    :return args: commandline arguments for script\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    parser.add_argument(\"-d\", \"--dataset\", required=True,\n",
    "            help=\"path to input dataset of images\")\n",
    "    parser.add_argument(\"-m\", \"--model\", required=True,\n",
    "            help=\"path to output trained model\")\n",
    "    parser.add_argument(\"-l\", \"--label-bin\", required=True,\n",
    "            help=\"path to output label binarizer\")\n",
    "    parser.add_argument(\"-p\", \"--plot\", required=True,\n",
    "            help=\"path to output accuracy/loss plot\")\n",
    "    \"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser(description='Train a model to classify spectrograms')\n",
    "    parser.add_argument('-c', '--channel', dest='channel', type=int, required=True, choices=[4, 5, 8, 9, 10, 11, 16],\n",
    "                        help='Flag used to determine what channel we want to create a model for')\n",
    "    parser.add_argument('-s', '--set', dest='size', required=True,\n",
    "                        help='Flag used to determine the amount of experiments to import for train/test data')\n",
    "    parser.add_argument('-i', '--image-size', dest='image_size', required=True,\n",
    "                        help='Flag used to determine the length and width to resize the data spectrogram images')\n",
    "    parser.add_argument('-e', '--epochs', dest='epochs', required=True,\n",
    "                        help='Flag used to determine the number of epochs for training')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    return args\n",
    "\n",
    "\n",
    "def determine_data_paths(paths_to_datasets, channel, size):\n",
    "    \"\"\"\n",
    "    Function used to determine full paths to datasets we will be reading for training and testing\n",
    "    :param paths_to_datasets: path to root of data for DROWSY, FOCUSED, UNFOCUSED spectrograms\n",
    "    :param channel: channel we want to train a model for\n",
    "    :param size: number of experiments we want to input for test/train data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    all_paths = []\n",
    "\n",
    "    for path_to_dataset in paths_to_datasets:\n",
    "        path_with_channel = os.path.join(path_to_dataset, str(channel))\n",
    "        dirs = glob.glob(path_with_channel, recursive=True)\n",
    "\n",
    "        # TODO: need to figure out a way to get the same eeg_records dirs for each class (DROWSY, FOCUSED, UNFOCUSED)\n",
    "        image_paths = sorted(list(dirs))\n",
    "        image_paths = image_paths[:size]\n",
    "\n",
    "        all_paths.extend(image_paths)\n",
    "\n",
    "    return all_paths\n",
    "\n",
    "\n",
    "def get_all_image_paths(all_root_paths):\n",
    "    \"\"\"\n",
    "    Function used to get all spectrogram image paths from a list of root directories\n",
    "    example: './DROWSY/eeg_record/4' gets all images at path 'DROWSY/eeg_record/4/*png'\n",
    "    :param all_root_paths:\n",
    "    :return all_image_paths: complete paths to all images we are going to input for train/test data\n",
    "    \"\"\"\n",
    "    all_image_paths = []\n",
    "\n",
    "    for root_path in all_root_paths:\n",
    "        png_path = os.path.join(root_path, '*.png')\n",
    "        image_paths = glob.glob(png_path, recursive=True)\n",
    "\n",
    "        all_image_paths.extend(image_paths)\n",
    "\n",
    "    return all_image_paths\n",
    "\n",
    "def get_train_test_data(images_path_list, image_size):\n",
    "    \"\"\"\n",
    "    Function used to get all train and test images and label data\n",
    "    :param images_path_list: list of all images we want to read\n",
    "    :param image_size: image resize to save computation time\n",
    "    :return data, labels: data with their labels (e.g., DROWSY, FOCUSED, UNFOCUSED)\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for image_path in images_path_list:\n",
    "        image_src = np.asarray(Image.open(image_path).resize((image_size, image_size)).convert('RGB'))\n",
    "        data.append(image_src)\n",
    "\n",
    "        label = image_path.split(os.path.sep)[-4]\n",
    "        labels.append(label)\n",
    "\n",
    "    data = np.array(data, dtype='float') / 255.0\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main Enterance of model\n",
    "    \"\"\"\n",
    "\n",
    "    # handle arguments\n",
    "    args = handle_arguments()\n",
    "\n",
    "    print('-------------------------\\n[INFO] Preprocessing Data\\n-------------------------')\n",
    "\n",
    "    # Get all paths we want to read data from\n",
    "    data_paths = determine_data_paths(PATH_TO_DATASET, args.channel, int(args.size))\n",
    "\n",
    "    all_image_paths = get_all_image_paths(data_paths)\n",
    "\n",
    "    data_set, labels = get_train_test_data(all_image_paths, int(args.image_size))\n",
    "\n",
    "    print('-------------------------\\n[INFO] Building Model\\n-------------------------')\n",
    "\n",
    "    # split training and test data\n",
    "    (trainX, testX, trainY, testY) = train_test_split(data_set, labels, test_size=0.25, random_state=42)\n",
    "\n",
    "    lb = LabelBinarizer()\n",
    "    trainY = lb.fit_transform(trainY)\n",
    "    testY = lb.transform(testY)\n",
    "\n",
    "    # building model\n",
    "    model = Sequential()\n",
    "\n",
    "    # adding layers\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(int(args.image_size), int(args.image_size), 3), activation=ACTIVATION))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation=ACTIVATION))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(64, activation=ACTIVATION))\n",
    "\n",
    "    # prediction layer, using softmax because we are expecting more than two outcomes (DROWSY, FOCUSED, UNFOCUSED)\n",
    "    model.add(Dense(3, activation=PREDICT_ACTIVATION))\n",
    "    model.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "    print('-------------------------\\n[INFO] Train Model\\n-------------------------')\n",
    "\n",
    "    history = model.fit(trainX, trainY, epochs=int(args.epochs), validation_data=(testX, testY), batch_size=300)\n",
    "\n",
    "    print('-------------------------\\n[INFO] Plot Results\\n-------------------------')\n",
    "\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim([0.5, 1])\n",
    "    plt.legend(loc='lower right')\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(testX, testY, verbose=2)\n",
    "\n",
    "    print('Test Loss: {test_loss}'.format(test_loss=test_loss))\n",
    "    print('Test Accuracy: {test_acc}'.format(test_acc=test_acc))\n",
    "    print(test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -c {4,5,8,9,10,11,16} -s SIZE -i IMAGE_SIZE -e EPOCHS\n",
      "ipykernel_launcher.py: error: the following arguments are required: -c/--channel, -s/--set, -i/--image-size, -e/--epochs\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Apps\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "args = handle_arguments()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
